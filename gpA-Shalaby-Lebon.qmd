---
title: "Rapport d'analyse de données"
author: 
  - name: "Youssef SHALABY"
  - name: "Lyse LEBON"
date: "`r Sys.Date()`"
format: 
  pdf:
    toc: TRUE
    toc_depth: 2
    number-sections: true
    header-includes:
    - \usepackage{color}
    - \newcommand{\X}{\mathbf{X}}
execute: 
  echo: false 
  warning: false
  message: false
---

```{r} 

library(ggplot2)
library(corrplot)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(kableExtra)
library(knitr)
library(reshape2)
library(tinytex)
library(forcats)
library(vcd)
library(patchwork)
library(dplyr)
library(tidyr)

#Pour le clustering 
library(mclust)
library(cluster)
library(ppclust)
library(circlize)
library(ggalluvial)
library(clusterSim)
library(viridis)
library(seriation)
```
# Introduction 

Dans ce rapport, nous allons étudier un jeu de données fournissant un aperçu détaillé des routines d'exercice, des attributs physiques et des mesures de la condition physique (_les modalités_) de 973 membres d'une salle de sport (_les individus_). Ces individus sont répertoriés dans une base de données nommée "DataGym3MIC" que nous avons renommée pour la suite "gym". 

**\textcolor[HTML]{8DA0CB}{Lorsqu'il y aura la présence de ce signe : [Q], cela signifiera qu'il y a un complément sur le document quarto}**. 

Dans cet échantillon, nous retrouvons deux types de données : les données **qualitatives** ("gender" [nominale] et "level" [ordinale]) et les données **quantitatives continues** ("weight", "height", "duration", "calories", "fat", "water" et "bmi"). Nous avons affiché le sommaire des données sur la @tbl-sommaire.  

\tiny
```{r}
#| echo: false
#| label: tbl-sommaire
#| tbl-cap: "Les premières lignes du jeu de données Gym"

gym <- read.table("DataGym3MIC.txt",header=TRUE)
kable(summary(gym))

```
\normalsize

Nous avons spécifié à R que les deux variables gender et level étaient des variables qualitatives et nous avons également renommé les niveaux avec "débutant", "intermédiaire" et "avancé". 
```{r}
gym$level <- factor(gym$level, 
                    levels = c(1, 2, 3), 
                    labels = c("Débutant", "Intermédiaire", "Avancé"))
gym$gender <- as.factor(gym$gender)
```


# Statistique uni et bi-dimensionnelle 

## Étude statistique unidimensionnelle 

### Cas des variables qualitatives 

Dans cette partie, nous nous focaliserons sur les deux variables qualitatives **"gender"** et **"level"**.

Tout d'abord, pour la variable **"gender"**, qualitative nominale. On constate sur la @fig-sexe, qu'un peu plus de $50$% des inscrits à la salle sont des hommes. La répartition des sexes dans cette salle est équilibrée. 

```{r}
#| echo: false
#| fig-cap: "Diagramme en bâtons des différents niveaux (gauche) et graphe camembert de la répartition homme/femme (droite)"
#| label: fig-sexe
#| fig-height: 2

level_data <- gym %>%
  group_by(level) %>%
  summarise(count = n()) %>%
  mutate(freq = count / sum(count))

g1 <- ggplot(level_data, aes(x = level, y = freq, fill =level)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set2") +
  geom_text(aes(label = paste0(round(freq * 100, 1), "%")), 
            vjust = -0.5, 
            color = "black", 
            size = 4) +
  
  ylab("")+
  ggtitle("Fréquences par niveau")+ 
  scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +
  theme_minimal()

df <- as.data.frame(table(gym$gender))
colnames(df) <- c("gender", "count")
df$freq <- df$count / sum(df$count)
df$legende <- paste0(df$gender, 
                    " (", 
                    round(df$freq * 100, 1), 
                    "%)")
df$pos <- cumsum(df$freq) - df$freq/2
g4 <- ggplot(df, aes(x = "", y = freq, fill = legende)) + 
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  labs(title = "Fréquences par genre", x = NULL, y = NULL, fill = "genre") + 
  theme_void() + 
  scale_fill_brewer(palette = "Set2")
grid.arrange(g1,g4,ncol=2, widths = c(1.5, 1))

```

La variable **"level"** est une variable qualitative ordinale. On peut donc utiliser les fréquences afin de poursuivre l'étude. Nous avons choisi pour la @fig-sexe de n'afficher que le camembert et le diagramme en bâtons car ils nous permettent de comprendre rapidement les valeurs des deux variables. 

On constate avec la @fig-sexe qu'il y a presque autant de débutants que d'intermédiaires et qu'ils sont plus nombreux que les avancés (plus de $75$%). Ces résultats sont cohérents puisque maîtriser un sport demande beaucoup de temps et de persévérance. 


### Cas des variables quantitatives 

Dans cette partie, nous allons analyser les Boxplot de toutes les variables quantitatives et en extraire quelques-uns qui peuvent être intéressants. 

```{r}
#| echo: false
#| fig-cap: "Visualisation de la répartition de toutes les variables quantitatives de gym par des violin plot"
#| label: fig-boxtout
#| fig-height: 3

make_plot <- function(data_frame, cols, title) { 
  d_long <- data_frame %>% 
    dplyr::select(all_of(cols)) %>% 
    pivot_longer(cols = everything(), names_to = "variable", values_to = "value")
  ggplot(d_long, aes(x = variable, y = value, fill=variable)) +
    geom_violin(trim = FALSE, scale = "width")+
    scale_fill_brewer(palette = "Set2")+
    geom_boxplot(width = 0.1, fill = "white") + 
    labs(title = title, x = "", y = "value") +
    theme_minimal() +
    theme(legend.position = "none", 
          plot.title = element_text(size = 10))
}
g1bis<- make_plot(gym, c("height", "duration", "water"),"")
g2bis<- make_plot(gym, c("bmi","fat"),"")
g3bis<- make_plot(gym, "calories","")
g4bis<- make_plot(gym, "weight","")

grid.arrange(g1bis,g2bis,g3bis,g4bis, ncol=4, widths = c(3,2,2,2))
```
Grâce à la @fig-boxtout, on constate que les différents quartiles des variables correspondent aux valeurs de la @tbl-sommaire. On observe également que les variables "weight", "calories" et "bmi" possèdent de nombreux outliers avec un étalement vers la droite. Dans le cadre de cette étude, nous allons conserver ces outliers qui restent pertinents dans le cadre d'une salle de sport. On constate également une forme particulière du violin plot de la variable "water". Nous allons désormais étudier plus en profondeur les variables "bmi" et "water".  
  

```{r}
#| echo: false
#| fig-cap: "Histogramme des fréquences pour la variable water (à droite) et bmi (à gauche)"
#| label: fig-boxwei
#| fig-height: 2
g1<-ggplot(gym,aes(x=bmi))+
  geom_histogram(aes(y=..density..),bins=250,color="black", fill="white")+
  ggtitle("Histo. des fréquences")+
  ylab("Density")+xlab("Bmi")
g2<-ggplot(gym,aes(x=water))+
  geom_histogram(aes(y=..density..),bins=250,color="black", fill="white")+
  ggtitle("Histo. des fréquences")+
  ylab("Density")+xlab("Water")
grid.arrange(g1,g2,ncol=2)
```
Analysons alors leurs histogrammes afin de comprendre ces valeurs "aberrantes". 
D'après la @fig-boxwei, on constate en effet un fort étalement vers la droite pour la variable "bmi". Cet étalement peut s'expliquer par le fait que les inscrits à la salle développent du muscle (et perdent du gras), mais leur IMC reste élevé, voire augmente. Un autre facteur serait que des inscrits viennent à la salle afin de perdre du poids et ont donc un IMC élevé. 
Les deux pics sur l'histogramme de la variable "water" peuvent s'expliquer par le fait qu'il y ait des inscrits qui font des séances très longues (d'où la nécessité de boire beaucoup). On pourrait également soumettre l'hypothèse que les niveaux avancés prennent de la créatine, des protéines ou des électrolytes qui nécessitent un apport d'eau important. Le fait que cette courbe ne soit pas lisse pourrait s'expliquer par le fait qu'il s'agisse peut-être d'une variable discrétisée, les inscrits arrondissent leur consommation à des bouteilles de 0,5L ou 1,5L. 


## Étude statistique bi-dimensionnelle 

### Étude entre deux variables qualitatives 

Dans cette partie, nous analysons les deux variables qualitatives "level" et "gender". Grâce à la @tbl-TableContingence, nous pouvons observer la table de contingence de ces deux variables. 
```{r}
#| echo: false
#| label: tbl-TableContingence
#| tbl-cap: "Matrice de contingence entre level et sexe"
kable(addmargins(table(gym$gender,gym$level)),align='c')
```
On constate toujours qu'il y a presque autant d'hommes que de femmes mais que, malgré tout, les hommes restent plus présents dans tous les niveaux confondus. 

```{r}
#| echo: false
b=assocstats(table(gym$gender,gym$level))
V = b$cramer
```

L'indice de Cramér = `r round(V,4)` est quasiment nul, on en conclut que la liaison est très peu significative.  Ainsi, on en déduit que dans ce club de gym, le niveau de compétence ("level") des individus est indépendant du genre ("gender").  


### Étude entre une variable qualitative et une quantitative


Dans cette partie nous avons décidé d'analyser la variable "level" avec la variable "fat" ainsi que la variable "level" avec la variable "duration". En effet, nous pensons que ces deux couples sont fortement liés.  Vérifions ce prédicat à l'aide de la @fig-box. 
```{r}
#| echo: false
#| label: fig-box
#| fig-cap: "Boxplot entre level et fat (à gauche) et entre level et duration (à droite)"
#| fig-height: 2
g1<- ggplot(gym,aes(x=level,y=fat, color = level))+
  geom_boxplot() + 
  scale_color_brewer(palette = "Set2") +
  theme_minimal()+
  theme(legend.position = "none")

g2<- ggplot(gym,aes(x=level,y=duration, color = level))+
  geom_boxplot() + 
  scale_color_brewer(palette = "Set2") +
  theme_minimal()+
  theme(legend.position = "none")
grid.arrange(g1,g2,ncol=2)
```

Après la création du boxplot de la @fig-box pour ces deux couples, on constate bien qu'il y a une forte liaison entre la variable "level" et la variable "fat". En effet, bien que pour les débutants et intermédiaires le boxplot est plutôt similaire, on constate une nette différence avec le niveau avancé.  
Idem pour la variable "level" et "duration", on peut constater la même chose que précédemment: il y a une nette différence entre les boxplots pour les deux premiers niveaux avec celui du niveau avancé.  
**\textcolor[HTML]{8DA0CB}{[Q]}**.  

<!--Il y a d’autres variables qui présentent également un lien, cette fois un peu plus faible, entre gender et height, gender et fat, ou encore gender et water.

```{r}
#| echo: false
g1<- ggplot(gym,aes(x=level,y=weight))+
  geom_boxplot()+theme_minimal()
g2<- ggplot(gym,aes(x=level,y=height))+
  geom_boxplot()+theme_minimal()
g3<- ggplot(gym,aes(x=gender,y=weight))+
  geom_boxplot()+theme_minimal()
g4<- ggplot(gym,aes(x=level,y=calories))+
  geom_boxplot()+theme_minimal()
g5<- ggplot(gym,aes(x=level,y=water))+
  geom_boxplot()+theme_minimal()
g6<- ggplot(gym,aes(x=level,y=bmi))+
  geom_boxplot()+theme_minimal()
g7<- ggplot(gym,aes(x=gender,y=height))+
  geom_boxplot()+theme_minimal()
g8<- ggplot(gym,aes(x=gender,y=duration))+
  geom_boxplot()+theme_minimal()
g9<- ggplot(gym,aes(x=gender,y=calories))+
  geom_boxplot()+theme_minimal()
g10<- ggplot(gym,aes(x=gender,y=fat))+
  geom_boxplot()+theme_minimal()
g11<- ggplot(gym,aes(x=gender,y=water))+
  geom_boxplot()+theme_minimal()
g12<- ggplot(gym,aes(x=gender,y=bmi))+
  geom_boxplot()+theme_minimal()
grid.arrange(g1,g2,g3, g4,g5,g6,g7,g8,g9, g10,g11,g12, ncol=3)
```
-->
```{r}
rapp2 <-BioStatR::eta2(x = gym$fat, y = gym$level)
rapp3 <-BioStatR::eta2(x = gym$duration, y = gym$level)
```
```{r}
#| echo: false
#| label: tbl-corr
#| tbl-cap: "Les rapports de correlation entre les variables quantitatives et qualitatives"
vars_quanti <- c("height", "weight", "duration", "calories", "fat", "bmi", "water")
vars_quali  <- c("gender", "level")
corr <- matrix(NA, nrow = length(vars_quali), ncol = length(vars_quanti))
rownames(corr) <- vars_quali
colnames(corr) <- vars_quanti
for (quanti in vars_quanti) {
  for (quali in vars_quali) {
    corr[quali, quanti] <- round(summary(lm(gym[[quanti]] ~ gym[[quali]]))$r.squared,4)
  }
}
df_couleur <- as.data.frame(corr)
df_couleur["level", "fat"] <- cell_spec(df_couleur["level", "fat"], 
                                            color = rgb(0.6, 0.9, 0.6), 
                                            bold = TRUE)
df_couleur["level", "duration"] <- cell_spec(df_couleur["level", "duration"], 
                                             color = rgb(1.0, 0.7, 0.4), 
                                             bold = TRUE)
kbl(df_couleur, escape = FALSE) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))

```
Grâce à la @tbl-corr, qui affiche le rapport de corrélation entre toutes les variables quantitatives avec toutes les variables qualitatives, nous pouvons maintenant analyser si nos deux couples ont un rapport de corrélation faible ou important. Le rapport de corrélation entre "fat" et "level" (en vert dans la @tbl-corr) est de : `r round(rapp2,4)`  et le rapport entre "duration" et "level" (en orange dans la @tbl-corr) est de: `r round(rapp3,4)`. On constate ainsi que les variables "fat" et "level" ainsi que duration et "level" sont fortement corrélées (le rapport de correlation est proche de 1). 
Ces valeurs paraissent logiques. En effet, plus on a un bon niveau dans un sport, plus on est apte à durer longtemps. Idem, plus on fait de sport, moins on a de graisse.  
On peut également observer un rapport de corrélation élevé entre les variables "level" et "calories" ainsi que les variables "water" et "gender".  


### Étude entre deux variables quantitatives 

Nous allons poursuivre cette partie en faisant l'étude des variables qui sont le plus corrélées, comme le montre la @fig-corrplot. 
```{r}
#| echo: false
#| label: fig-corrplot
#| fig-cap: "Matrice de corrélation des 7 variables quantitatives"
#| fig-height: 3

col_set2_gradient <- colorRampPalette(c("#FC8D62", "white", "#8DA0CB"))(200)
corrplot(cor( gym[,-c(1,8)]), method="ellipse",   
         col = col_set2_gradient,
         tl.col = "#FC8D62",         
         tl.srt = 90, 
         cl.pos = "r"   )
```
À l'aide de la @fig-corrplot, on constate que la variable "fat" est fortement corrélée négativement avec "duration", "calories" et "water". La variable "bmi" est corrélée positivement avec "weight" ou encore la variable "calories" avec "duration".  
  
Grâce à la forte corrélation entre certaines variables quantitatives, il est pertinent de mener une Analyse en Composantes Principales (ACP). Cela permettra de résumer l'information en éliminant le bruit et la redondance, et de visualiser la structure des données sur un plan factoriel.  


# Analyse en Composantes Principales 

Dans cette section, nous allons faire une Analyse en Composantes Principales sur les données centrées réduites.  
Nos variables étant exprimées dans des unités de mesure hétérogènes (poids, temps, calories), l'ACP centrée réduite est indispensable. Elle permet de standardiser les données et ramène toutes les variables à une variance unitaire, ce qui revient à analyser la matrice des corrélations. Cela garantit que chaque variable contribue de manière équitable à la construction des axes factoriels.  
  
L'inertie globale du nuage de point notée $\mathcal{J}$, est, dans notre cas d'étude avec des données centrées réduites, égale au nombre de variables quantitatives, ici $\mathcal{J}$ = $7$ (on veut calculer la trace de $\Gamma$M qui est la matrice des corrélations [qui vaut 1 sur la diagonale]).  
Cette valeur représente la quantité d'information disponible que nous cherchons à résumer.  
Par la suite, on nommera notre jeu de données centré et réduit GymCR.

```{r}
GymC<-scale(gym[,-c(1,8)] , scale = FALSE)
GymCR<-scale(gym[,-c(1,8)])
```

## Choix du nombre d'axes factoriels

```{r}
#| label: fig-screeplotCR
#| fig-cap: "Pourcentage d'inertie expliquée par les axes factoriels"
#| fig-height: 3
respca2<-PCA(gym,quali.sup=c(1,8),scale.unit=T,graph=F)
fviz_eig(respca2, addlabels = TRUE,ylim = c(0, 50),
         barfill = rgb(1.0, 0.7, 0.4), barcolor = rgb(1.0, 0.7, 0.4))
```
Grâce à l'ACP centrée réduite, sur la @fig-screeplotCR, on constate que l'étude des variables quantitatives est portée par au moins 3 dimensions (la somme des trois pourcentages vaut $85,9$%). Cela signifie que l’essentiel de
l’information contenue dans les données peut être visualisé dans un espace tridimensionnel.  
  
```{r}
L1 = 0.415*7
L2 = 0.268*7
L3 = 0.176*7
```

Remarque : La décomposition de l'inertie globale sur les axes factoriels, observée dans la @fig-screeplotCR, nous donne les inerties axiales, correspondant aux valeurs propres de la matrice de corrélation. L'axe 1 capture une inertie axiale de $\lambda_1$ = `r round(L1,4)`, l'axe 2, lui, capture une inertie axiale de $\lambda_2$ = `r round(L2,4)` et l'axe 3 $\lambda_3$ = `r round(L3,4)`. Ainsi, notre réduction dimensionnelle préserve `r round((L1+L2+L3)*100/7,4)`% de la variance du jeu de données original.

## Analyse de la distribution des variables quantitatives selon les différents axes factoriels

Comme nous ne pouvons pas projeter en 3D, nous allons d'abord faire l'analyse du premier plan factoriel, puis le plan factoriel porté par l'axe factoriel 1 et l'axe factoriel 3.  
```{r}
#| label: fig-grapheCR
#| fig-cap: "Cercles des corrélations des variables quantitatives projetées sur les plans factoriels (1,2) et (1,3)"
#| fig-height: 3

groupes_vars <- rownames(respca2$var$coord)
Z1 <- fviz_pca_var(respca2, 
                   axes = c(1, 2),
                   col.var = groupes_vars, 
                   palette = "Set2",
                   repel = TRUE) +
      theme_minimal() +
      theme(legend.position = "none", 
            panel.grid.major = element_line(color = "grey70"),
            panel.grid.minor = element_line(color = "grey90")) +
      ggtitle("Cercle des corrélations\n(Axes 1 et 2)")
Z2 <- fviz_pca_var(respca2, 
                   axes = c(1, 3), 
                   col.var = groupes_vars,
                   palette = "Set2",
                   repel = TRUE) +
      theme_minimal() +
      theme(legend.position = "none",
            panel.grid.major = element_line(color = "grey70"),
            panel.grid.minor = element_line(color = "grey90")) +
      ggtitle("Cercle des corrélations\n(Axes 1 et 3)")

grid.arrange(Z1, Z2, ncol = 2)
```
Ainsi avec la @fig-grapheCR, on constate que la distribution des variables est équitablement répartie pour les $2$ associations différentes, les dimensions ne sont pas définies par une seule variable. 

```{r}
#| label: fig-matcordim
#| fig-cap: "Matrice de corrélation entre les variables initiales et les méta-variables "
#| fig-height: 3
col_set2_gradient <- colorRampPalette(c("#FC8D62", "white", "#8DA0CB"))(200)
matrice_pour_graphe <- t(respca2$var$cor)
corrplot(matrice_pour_graphe,
         method = "ellipse", 
         col = col_set2_gradient,
         tl.col = "#FC8D62",          
         tl.srt = 90, 
         cl.pos = "r"   
)
```

\underline{Analyse du premier axe}  
Grâce à la @fig-matcordim, on constate que le premier axe factoriel est fortement corrélé positivement avec la variable "calories" et corrélée positivement avec la variable "duration". Il est également corrélé négativement avec la variable "fat". On peut donc supposer que le premier axe structure l'échantillon selon le niveau d'entraînement.  
Afin de faire le lien avec la @fig-grapheCR (à l'aide du graphique de gauche), on retrouve à droite les individus qui s'entraînent longtemps, brûlent beaucoup de calories et boivent beaucoup d'eau. À gauche, on trouve les individus ayant un taux de graisse élevé. Cela traduit une logique physiologique : plus l'intensité sportive est élevée, plus le taux de graisse tend à être bas.

\underline{Analyse du deuxième axe}   
Grâce à la @fig-matcordim, on constate que le deuxième axe factoriel est corrélé positivement avec les variables "weight" (très forte corrélation) et "bmi". Il peut représenter la corpulence brute des individus. 
Sur la @fig-grapheCR (à l'aide du graphique de gauche), on retrouve en haut les individus lourds et à fort IMC  et en bas, les individus légers.

\underline{Analyse du troisième axe}  
Grâce à la @fig-matcordim, on constate que le troisième axe factoriel est corrélé négativement avec la variable "height". D'après la @fig-grapheCR, il est presque exclusivement défini par la taille mais de façon inversée (les grands en bas).  
  
On note un phénomène intéressant avec le BMI : il est corrélé positivement au deuxième axe et au troisème axe. C'est mathématiquement logique car la formule de l'IMC est $Poids / Taille^2$. L'ACP a permis la décomposition de l'IMC en ses deux composantes primaires: le poids sur l'axe 2 et la taille sur l'axe 3.

```{r}
#| label: fig-contrib
#| fig-cap: "Graphique des contributions des variables quantitatives pour la dim 1 (gauche), dim 2 (centre) et la dim 3 (droite)"
#| fig-height: 3
res.pca <- PCA(gym[, c("weight", "height", "duration", "calories", "fat", "water", "bmi")], 
               scale.unit = TRUE, 
               graph = FALSE)

seuil_theorique <- 100 / 7

# Graphique pour la Dimension 1
p1 <- fviz_contrib(res.pca, choice = "var", axes = 1, 
             top = 7, # On affiche les 7 variables
             title = "Dim 1",
             color = "#8DA0CB", fill = "#8DA0CB") +
      geom_hline(yintercept = seuil_theorique, linetype = "dashed", color = "darkred")

# Graphique pour la Dimension 2
p2 <- fviz_contrib(res.pca, choice = "var", axes = 2, 
             top = 7,
             title = "Dim 2",
             color = "#FC8D62", fill = "#FC8D62") +
      geom_hline(yintercept = seuil_theorique, linetype = "dashed", color = "darkred")

# Graphique pour la Dimension 3 (puisque vous la gardez)
p3 <- fviz_contrib(res.pca, choice = "var", axes = 3, 
             top = 7,
             title = "Dim 3",
             color = "#66C2A5", fill = "#66C2A5") +
      geom_hline(yintercept = seuil_theorique, linetype = "dashed", color = "darkred")

# Affichage des graphiques (vous pouvez utiliser grid.arrange pour les grouper)
grid.arrange(p1,p2,p3,ncol =3)

#print(res.pca$var$contrib)
```
Ainsi, grâce à la @fig-contrib et l'analyse faite avec la @fig-grapheCR, on constate que les variables citées contribuent fortement avec les différentes dimensions. On peut observer que le premier axe est aussi construit par la variable "water" et le deuxième axe est également definit par la variable "duration", qui ne se voyait pas dans les @fig-grapheCR et @fig-matcordim. 

# Clustering 

Dans cette partie, nous allons essayer de partitionner un ensemble de données en sous-groupes homogènes. Nous allons tenter de minimiser la variance intra-classe et de maximiser la variance inter-classe.  


## Méthode de type K-means

```{r}
#ACP Centrée Reduite
resacpCR <- PCA(gym,quali.sup=c(1,8), scale.unit = TRUE,graph=FALSE)

# ACP centrée seulement
resacpC <- PCA(gym,quali.sup=c(1,8), scale.unit = FALSE,graph=FALSE)
```
Dans cette section nous allons aborder la méthode des K-means, un algorithme d'apprentissage non supervisé. Son but est de segmenter la population de la salle de sport afin d'identifier des profils types. 


### Choix du nombre de classes 

Le choix du nombre de classes K peut se déterminer grâce aux critères suivants: le critère du coefficient de Silhouette et le critère Inertie Intra. L’analyse de la @fig-nbrclasse montre que la valeur optimale est K=$3$, correspondant au maximum observé sur la figure de gauche. On retrouvera sur la figure de droite la valeur K=$6$, correspondant au coude sous la figure. 


```{r}
#| label: fig-nbrclasse
#| fig-cap: "Méthode Silhouette (gauche) et Inertie intra-classe (droite)"
#| fig-height: 2

set.seed(23)
y=scale(gym[,-c(1,8)])
Kmax<-15
reskmeanscl<-matrix(0,nrow=nrow(gym),ncol=Kmax-1)
Silhou<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(y,k, nstart = 15)
  reskmeanscl[,k-1]<-resaux$cluster
   aux<-silhouette(reskmeanscl[,k-1], daisy(y))
   Silhou<-c(Silhou,mean(aux[,3]))
}

df<-data.frame(K=2:Kmax,Silhouette=Silhou)
e1<- ggplot(df,aes(x=K,y=Silhouette))+
  geom_point(color = "#FC8D62", size = 2)+
  geom_line(color = "#FC8D62")+theme(legend.position = "bottom") +
  theme_minimal()+
  theme(panel.grid.major = element_line(color = "gray80"))

#----
reskmeanscl<-matrix(0,nrow=nrow(gym),ncol=Kmax-1)
Iintra<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(GymCR,k, nstart = 5)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss)
}

df<-data.frame(K=2:15,Iintra=Iintra)
e2<- ggplot(df,aes(x=K,y=Iintra))+
  geom_line(color = "#8DA0CB")+
  geom_point(color = "#8DA0CB", size = 2)+
  xlab("Nombre de classes")+
  ylab("Inertie intra-classe")+
  theme_minimal()+
  theme(panel.grid.major = element_line(color = "gray80"))
grid.arrange(e1,e2, ncol = 2)
```

```{r}
set.seed(23)
trois <- kmeans(y,3)
troisgen=adjustedRandIndex(trois$cluster,gym$gender)
troislev= adjustedRandIndex(trois$cluster,gym$level)

six <- kmeans(y,6)
sixgen=adjustedRandIndex(six$cluster,gym$gender)
sixlev= adjustedRandIndex(six$cluster,gym$level)

```
Afin de déterminer si on conserve K = $3$ ou $6$, nous allons comparer les mesures d’agrégation pour ces deux valeurs. Pour K = $3$ on obtient: `r round(troisgen,4)` pour gender et `r round(troislev,4)` pour level. Pour K = $6$ on obtient: `r round(sixgen,4)` pour gender et `r round(sixlev,4)` pour level.
Les mesures d'agrégation obtenues ne nous permettent pas de conclure sur le choix de K.

```{r}
#| label: tbl-TableContingencekmeans
#| tbl-cap: "Matrice de contingence croisant la partition en 3 classes et la partition en 6 classes"
#| fig-height: 2

table_croisee <- table(K3 = trois$cluster, K6 = six$cluster)
df_table <- as.data.frame(table_croisee)
ggplot(df_table, aes(x = K6, y = K3, fill = Freq)) +
  geom_tile(color = "white") + # Les cases colorées
  geom_text(aes(label = ifelse(Freq > 0, Freq, "")), color = "black", size = 5) + # Les chiffres (on cache les 0)
  scale_fill_gradient(low = "white", high = "#FFC067") +
  scale_x_discrete(name = "Partition en 6 classes") +
  scale_y_discrete(name = "Partition en 3 classes") +
  theme_minimal() +
  theme(legend.position = "none", # On cache la légende de couleur inutile ici
        panel.grid = element_blank())

```
Grâce à la @tbl-TableContingencekmeans, on constate que le premier groupe (lié au clustering pour K=3) se retrouve majoritairement dans le deuxième groupe (lié au clustering pour K=6). Idem, le deuxième groupe (lié au clustering pour K=3) se retrouve majoritairement dans le troisième (lié au clustering pour K=6). Le dernier groupe (lié au clustering K=3) est répartit dans les groupes 1, 4 et 6 du clustering pour K=6. La répartition en $6$ classes peut ainsi se retrouver facilement à partir de K=$3$. On en conclut qu'il y a peu de perte d'information. 

On observe sur la @fig-silhouette avec K=$3$ qu'on obtient un coefficient de silhouette moyen de 0,31, ce score indique une structure de clustering relativement faible.  
Ce résultat suggère qu'il n'y a pas de groupes naturellement disjoints dans la salle de sport.  
Toutefois, l'analyse des trois classes formées nous permet de comprendre la répartition des individus.  

Toujours sur la @fig-silhouette, la deuxième classe (en orange) est la plus large des trois et au dessus de la moyenne. Elle pourrait représenter les utilisateurs typiques qui sont compris entre le premier et le troisième quartile. La troisème classe (en violet) comporte des valeurs négatives qui représente des individus mal classés. Ceux-ci se rapprochent plus de la première ou la deuxième classe. Ces valeurs pourraient représenter les individus qui changent de niveau: de débutant vers intermédiaire ou de intermédiaire vers expert.  
Enfin, la première classe (en vert) semble également former un groupe distinct: elle possède des valeurs au dessus de la moyenne et elles sont toutes positives. Toutefois, elle est de taille plus fine.  
Ainsi, la première et deuxième classe sont bien identifiées contrairement à la troisième classe
qui manque de stabilité, ce qui pourrait expliquer la valeur de la moyenne globale.
Ces résultats mettent en évidence la complexité de notre jeux de données.

Ainsi avec K=$6$ la @fig-silhouette montre qu'on obtient un coefficient de silhouette moyen de 0,24 (bien plus faible que pour la valeur de K précédente).
On constate que cinq classes comportent des valeurs négatives correspondant à des individus mal classés. De plus, les épaisseurs des classes 1, 3, 4 et 5 sont  minimes, ce qui indique que peu d'individus se trouvent dans ces classes. 
La répartition des individus dans ces $6$ classes semble plus légère et moins efficace que l'analyse faite précédemment.  
Ainsi, on poursuivra cette étude avec K=$3$.  

```{r}
#| label: fig-silhouette
#| fig-cap: "Graphique des silhouettes des individus pour la classification retenue pour K=3 (gauche) et K=6 (droite)"
#| fig-height: 2

#on prend 2 car on a besoin de k-1 

auxtrois <- silhouette(reskmeanscl[,2], daisy(y))

figure1<- fviz_silhouette(auxtrois,print.summary = FALSE)+ 
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  theme(plot.title = element_text(size =9))

 auxquatre <- silhouette(reskmeanscl[,5], daisy(y))
figure2<- fviz_silhouette(auxquatre,print.summary = FALSE)+
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  theme(plot.title = element_text(size =9))

grid.arrange(figure1, figure2, ncol=2)
```

**\textcolor[HTML]{8DA0CB}{[Q]}**.
<!--

En comparant les deux graphes de la @fig-graphe36, on constate que cette figure est complémentaire à la @tbl-TableContingencekmeans. En effet, on observe que le groupe $1$ du graphique de gauche devient le groupe $2$, et que les groupes $2$ et $3$ sont répartis en deux groupes distincts ($2$ et $3$) sur le graphique de droite.

```{r}
#| label: fig-graphe36
#| fig-cap: "Répartition des individus en 3 classes(gauche) et 6 classes(droite) selon le premier plan factoriel"
#| fig-height: 3
graphe13 <- fviz_pca_ind(resacpCR,col.ind=as.factor(trois$cluster),
             geom = c("point"),axes=c(1,2))

graphe16<- fviz_pca_ind(resacpCR,col.ind=as.factor(six$cluster),
             geom = c("point"),axes=c(1,2))
grid.arrange(graphe13,graphe16, ncol = 2)
```
-->

### Analyse du clustering avec le nombre de classes retenu (3)


Maintenant que nous avons fixé le nombre de classe à K=$3$, nous pouvons analyser à quels critères (variables qualitatives) correspondent ces différentes classes.  

On observe sur @fig-cluster-visu-1 une distinction très nette pour la Classe 1, qui capte la quasi-totalité des profils "Avancé". Cela indique que l'algorithme a su isoler efficacement les performances élevées. En revanche, les Classes 2 et 3 se mélangent pour alimenter les catégories "Débutant" et "Intermédiaire". Ainsi on peut supposer qu'il est difficile de séparer ces deux niveaux en se basant uniquement sur les données physiologiques.

De même, la @fig-cluster-visu-2 met en évidence la répartition des genres au sein de nos groupes. Le résultat le plus marquant concerne la Classe 2, qui est composée exclusivement d'hommes (elle regrouperait les hommes débutants et intermédiaires). À l'inverse, la Classe 3 est majoritairement féminine, bien qu'elle comporte une portion masculine. Enfin, la Classe 1 (les sportifs performants ou de niveau avancé d'apres la @fig-cluster-visu-1) est mixte. Cela suggère que si le genre joue un rôle déterminant pour la Classe 2, la haute performance athlétique de la Classe 1 est, elle, indépendante du genre.  


```{r}
#| label: fig-cluster-visu
#| fig-cap: "Comparaison des classes selon le niveau (gauche) et le genre (droite)"
#| layout-ncol: 2
#| fig-subcap:
#|   - "Flux de répartition des individus entre les classes du clustering et les niveaux"
#|   - "Diagramme à cordes de la répartition du Genre par classe"
#| fig-height: 3

mes_couleurs <- c("#8DA0CB", "#FC8D62", "#66C2A5")
couleurs_genre <- c("#ff6961", "#A9CBD7")
toutes_les_couleurs <- c(mes_couleurs, couleurs_genre)

set.seed(23)
reskmeans <- kmeans(y, 3)
clust <- paste("Cl-K", reskmeans$cluster, sep="")

Tab <- melt(table(clust, gym$level))

ggplot(Tab, aes(y = value, axis1 = clust, axis2 = Var2)) +
  geom_alluvium(aes(fill = clust)) +
  geom_stratum(width = 1/12) +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  scale_fill_manual(values = mes_couleurs)+
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Flux Classe vs Niveau")

donnees_chord <- table(clust, gym$gender)
grid_colors <- setNames(mes_couleurs, rownames(donnees_chord))
col_genre <- setNames(rep("grey", ncol(donnees_chord)), colnames(donnees_chord))
chordDiagram(donnees_chord, 
             grid.col = toutes_les_couleurs)
circos.clear()
```

Pour ce qui est de l'influence des variables quantitatives sur les différents cluster, on peut s'appuyer sur la @fig-distributionkmeans. Ici, nous le ferons pour K=$3$ mais l'étude peut se faire aussi sur K=$6$.  
On constate que la première classe est constituée des individus qui restent longtemps à la salle, qui brûlent beaucoup de calories et qui ont peu de masse graisseuse (ce qui, d'après notre étude, s'apparente aux experts). Les deux autres classes sont presque similaires en terme d'influence des variables: elles comprennent les inscrits qui restent moins longtemps, avec un taux de graisse plus élévé et brûlent moins de calories. La seule petite différence peut se faire sur la quantité d'eau bue au cours de la séance qui est plus élévée pour la deuxième classe que pour la dernière. 


```{r}
#| label: fig-distributionkmeans
#| fig-cap: "Distribution des variables quantitatives pertinentes de 'gym' en fonction de la classification en 3 classes"
#| fig-height: 3

set.seed(23)
km3 <- kmeans(y, 3)
cols_k3 <- c("#66C2A5", "#FC8D62", "#8DA0CB")
df3 <- data.frame(GymCR[, -c(1, 2, 7)], Class = as.factor(km3$cluster))
df3 <- melt(df3, id = "Class")
ggplot(df3, aes(x = variable, y = value)) +
  geom_violin(aes(fill = Class)) +
  scale_fill_manual(values = cols_k3) +
  theme_minimal() +
  labs(title = "Distribution des variables", x = "", y = "Valeurs normalisées") +
  theme(legend.position = "top")

```


## Méthode de classification ascendante hiérarchique (CAH) 

La méthode CAH nous permet de construire un arbre complet des différentes classes et c'est à nous de "couper" l'arbre afin de choisir le nombre de groupe voulu. 

En observant la @fig-dendro, nous constatons que la fusion des individus se fait d'abord à faible distance, puis la fusion nécéssite des distances de plus en plus grandes. La hauteur du dendrogramme représente la distance minimale entre les deux classes précédentes.  
```{r}
#| label: fig-dendro
#| fig-cap: "Dendrogrammes du jeu de données gym avec la méthode Ward"
#| fig-height: 4
dx <- dist(GymCR, method = "euclidean")
hward<-hclust(dx,method = "ward.D2")

plot(hward,hang=-1,labels=FALSE)
#Nous n’en avons conservé qu’un seul par souci de lisibilité, car ils sont tous sensiblement similaires.
```
Grâce à la méthode de Calinski (à droite) affichée sur la @fig-SPRSQ, on analyse un pic à K=$3$. Pour cette méthode, on retient alors $3$ classes. Pour la méthode SPRSQ, on observe une décroissance rapide de l'inertie jusqu'à $4$ classes. Au-delà de ce point, la courbe s'aplatit, indiquant que l'ajout de groupes supplémentaires n'améliore que marginalement l'homogénéité de la partition. Nous retenons donc une solution à $4$ classes pour cette méthode.  

```{r}
#| label: fig-SPRSQ
#| fig-cap: "Détermination du nombre de classes grâce aux méthodes SPRSQ (à gauche) et Calinski-Harabasz (à droite)"
inertie_totale <- sum(hward$height)
sprsq_all <- hward$height / inertie_totale
n_fusion <- length(sprsq_all)
k_range <- 1:20
sprsq_top <- rev(sprsq_all)[k_range]
df_sprsq <- data.frame(k = k_range + 1, sprsq = sprsq_top)
limit_k <- 10
p1 <- ggplot(df_sprsq[df_sprsq$k <= limit_k, ], aes(x = k, y = sprsq)) +
  geom_line(color = "#FC8D62") +
  geom_point(color = "#FC8D62", size = 2) +
  labs(title = "Critère SPRSQ",
       x = "Nombre de classes (k)",
       y = "SPRSQ ") +
  scale_x_continuous(breaks = k_range + 1) + # Pour imiter xaxt="n" et axis(...)
  theme_minimal() +
  theme(panel.grid.major = element_line(color = "gray80"))

# Méthode Calinski 
CH<-NULL
Kmax<-20
for (k in 2:Kmax){
  CH<-c(CH,index.G1(x= GymCR, cl= cutree(hward, k=k)))
}
daux<-data.frame(NbClust=2:Kmax,CH=CH)
p2 <- ggplot(daux, aes(x = NbClust, y = CH)) +
  geom_line(color = "#8DA0CB") +
  geom_point(color = "#8DA0CB", size = 2) +
  labs(title = "Critère Calinski", x = "Nombre de classes (k)", y = "CH") +
  theme_minimal()+
  theme(panel.grid.major = element_line(color = "gray80"))

# Affiche p1 et p2 sur une ligne et deux colonnes
grid.arrange(p1, p2, ncol = 2)
```
**\textcolor[HTML]{8DA0CB}{[Q]}**
<!-- Pour la méthode SPRSQ, nous avons affiché K de $0$ à $10$ par souci de lisibilité sur le graphique. De plus, ces dernières valeurs ne sont pas utiles pour notre étude-->
```{r}
chb <- cutree(hward, k=3)
gen1=adjustedRandIndex(chb,gym$gender)
l1= adjustedRandIndex(chb,gym$level)

ch <- cutree(hward, k=4)
gen1b=adjustedRandIndex(ch,gym$gender)
l1b= adjustedRandIndex(ch,gym$level)
```
Afin de déterminer si on conserve K=$3$ ou $4$, nous allons comparer les mesures d'agrégation pour ces deux valeurs. La valeur obtenue avec la mesure d'agrégation en $4$ classes on obtient `r round(gen1b,4)` pour "gender" et `r round(l1b,4)` pour "level". Si on choisit $3$ classes on obtient `r round(gen1,4)` pour "gender" et `r round(l1,4)` pour "level", on peut donc en conclure que la répartition en $4$ classes n'est pas adaptée pour ces variables.  
Les valeurs de mesure d'agrégation sont plus importantes lorsqu'on utlise $3$ classes, nous allons ainsi rester sur ce nombre de classes par la suite. 

```{r}
#| label: fig-distributioncah
#| fig-cap: "Distribution des variables quantitatives pertinentes de 'gym' en fonction de la classification en trois classes"
#| fig-height: 4
couleurs_set2 <- c("#66C2A5", "#FC8D62", "#8DA0CB")
df<-data.frame(GymCR[, -c(2, 6)],Class=as.factor(chb))
df<-melt(df,id="Class")
ggplot(df,aes(x=variable,y=value))+
  geom_violin(aes(fill=Class))+
  scale_fill_manual(values = couleurs_set2) +
  theme_minimal() +
  labs(x = "Variables", y = "Valeurs normalisées")
```
Grâce à la @fig-distributioncah, on constate que la classe $1$ comporte les individus qui restent longtemps à la salle, qui brûlent beaucoup de calories et qui ont peu de masse graisseuse (comme sur la @fig-distributionkmeans). La classe $3$ comporte les individus qui pèsent lourds, avec une masse graisseuse plus importante (et donc un bmi élévé) et qui brûlent peu de calories. La classe $2$ et $3$ sont presque similaires, ce qui peu expliquer la difficulté à classer les individus de la salle de sport.
```{r}
#| label: fig-cluster-visuhierar
#| fig-cap: "Comparaison des classes avec le Niveau (gauche) et le Genre (droite)"
#| layout-ncol: 2
#| fig-subcap:
#|   - "Flux entre Clusters et Niveau"
#|   - "Répartition du Genre par Cluster"
#| fig-height: 3

mes_couleurs <- c("#8DA0CB", "#FC8D62", "#66C2A5")
couleurs_genre <- c("#ff6961", "#A9CBD7")
set.seed(23)
chb <- cutree(hward, k=3)
clust <- paste("Cl-K", chb, sep="")


Tab <- melt(table(clust, gym$level))

ggplot(Tab, aes(y = value, axis1 = clust, axis2 = Var2)) +
  geom_alluvium(aes(fill = clust)) +
  geom_stratum(width = 1/12) +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  scale_fill_manual(values = mes_couleurs)+
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Flux Clusters vs Niveau")
donnees_chord <- table(clust, gym$gender)

grid_colors <- setNames(mes_couleurs, rownames(donnees_chord))
col_genre <- setNames(rep("grey", ncol(donnees_chord)), colnames(donnees_chord))
chordDiagram(donnees_chord,grid.col = toutes_les_couleurs)
circos.clear()
```
Grâce à la @fig-cluster-visuhierar-1, on observe maintenant que la classe K1 est composée uniquement des individus de la salle qui sont avancés. On rentrouve ainsi dans la @fig-cluster-visuhierar-2 qu'il y a presque autant d'homme que de femme qui ont un niveau avancé. La classe K3 est uniquement composée d'hommes.  



## Comparaison de la méthode des K-means avec la classification hiérarchique 


```{r}
ClustCH<-cutree(hward,k=3)
y = scale(GymCR[,-c(1,8)])
reskmeansbsbs<-kmeans(y,3)
valeur = adjustedRandIndex(reskmeansbsbs$cluster, ClustCH)

```
Si on compare cette étude avec la méthode de K-means étudiée précédemment, on constate que `r round(valeur,4)*100`% des données sont classées de la même manière dans les deux méthodes.


```{r}
#| label: fig-alluvion
#| fig-cap: "Diagramme alluvial des correspondances entre les classes des K-means et de la CAH"
#| fig-height: 4
groupes_kmeans <- reskmeans$cluster

df_compare <- as.data.frame(table(
  Kmeans = paste("K-means", groupes_kmeans, sep=" "), 
  CAH = paste("CAH", ClustCH, sep=" ")
))

ggplot(df_compare, aes(y = Freq, axis1 = Kmeans, axis2 = CAH)) +
  geom_alluvium(aes(fill = Kmeans), width = 1/12) +
  geom_stratum(width = 1/12, fill = "grey95", color = "black") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), size = 3) +
  scale_fill_brewer(palette = "Set2") + 
  theme_minimal() +
  labs(title = "Flux de correspondance : K-means vs CAH",
       y = "Nombre d'individus",
       fill = "Groupe K-means d'origine") +
  theme(legend.position = "bottom")
```
Ainsi, grâce à la @fig-alluvion on constate que la répartition des individus dans les $3$ classes se ressemblent fortement entre les deux méthodes. On en conclut que la classification hiérarchique donne un résultat légèrement plus précis
pour la classification des niveaux (grâce à la @fig-cluster-visuhierar-1). 

# Conclusion 

L'analyse du jeu de données "Gym", portant sur 973 individus (avec plus ou moins la même quantité d'hommes que de femmes), nous a permis de dégager les profils types au sein de la salle de sport. Nous avons pu mettre en lumière plusieurs résultats majeurs.  

Premièrement, grâce à l'analyse bidimensionnelle on a démontré une indépendance entre le genre et le niveau. Être un homme ou une femme n'influe pas sur le fait d'être débutant ou avancé. En revanche, le niveau est fortement corrélé aux variables physiologiques : le niveau "avancé" se distingue nettement par une durée d'entraînement plus longue et un taux de graisse plus faible.  

Deuxièmement, l'Analyse en Composantes Principales nous a permis de structurer l'information selon trois méta-variables expliquant près de 86% de l'inertie.  
La première méta variable (41,5%) reflète l'intensité de l'entraînement (durée, calories brûlées contre le taux de graisse).  
La deuxième méta variable (26,8%) représente la corpulence (poids et IMC).  
La troisième méta variable ($17,6$%) reflète la taille des individus de la salle.  

Enfin, le clustering, mené comparativement via la méthode des K-means et la Classification  Hiérarchique (CAH), a convergé vers une partition optimale en 3 classes. Bien que le coefficient de silhouette moyen (0.31) indique une séparation des groupes relativement faible, l'interprétation des classes est riche de sens :
la classe "Performance" (Classe 1) regroupe quasi exclusivement les profils "Avancés". Fait notable : cette classe est mixte. Cela confirme que la haute performance athlétique lisse les différences de genre.
Deux classes "Loisirs/Intermédiaires" (Classes 2 et 3) : Ces groupes rassemblent les débutants et intermédiaires, qui sont difficilement séparables sur le plan physiologique. Ici, la distinction s'opère principalement par le genre, avec une classe majoritairement masculine et l'autre féminine.  

En conclusion, la classification hiérarchique s'est avérée légèrement plus précise que les K-means pour isoler les profils performants et les hommes des niveaux "débutants" et "intermédiaires".

